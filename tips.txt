import numpy as np  
import pandas as pd  
import torch  
import torch.nn as nn  
import torch.optim as optim  
from torch.utils.data import Dataset, DataLoader  
from sklearn.model_selection import train_test_split  
from sklearn.preprocessing import LabelEncoder  
from sklearn.metrics import classification_report, confusion_matrix  
import chardet  
import os  

def detect_encoding(file_path):  
    with open(file_path, 'rb') as f:  
        raw_data = f.read()  
    result = chardet.detect(raw_data)  
    return result['encoding']  

# 修改后的数据集类（不再包含LabelEncoder）
class TipDataset(Dataset):  
    def __init__(self, dataframe, transform=None):  
        self.data = dataframe  
        self.transform = transform  
        
    def __len__(self):  
        return len(self.data)  
    
    def __getitem__(self, idx):  
        npy_location = self.data.iloc[idx]['npy_location']  
        features = np.load(npy_location)  
        label_tip1 = self.data.iloc[idx]['tip1_encoded']  # 直接读取预编码的标签
        label_tip2 = self.data.iloc[idx]['tip2_encoded']  
        if self.transform:  
            features = self.transform(features)  
        return (
            torch.tensor(features, dtype=torch.float32),
            torch.tensor(label_tip1, dtype=torch.long),
            torch.tensor(label_tip2, dtype=torch.long)
        )

# ----------- 数据预处理流程修改 -----------
csv_path = r"E:\postgraduate\小论文\小论文\表格文件\id_tips_date_features.csv"  

# 1. 读取数据
encoding = detect_encoding(csv_path)
full_data = pd.read_csv(csv_path, encoding=encoding)

# 2. 先分割数据再编码（避免数据泄露）
train_df, test_df = train_test_split(full_data, test_size=0.2, random_state=42)

# 3. 在训练集上拟合编码器
label_encoder_tip1 = LabelEncoder()
label_encoder_tip2 = LabelEncoder()

# 创建编码后的列（原始列保留以便调试）
train_df['tip1_encoded'] = label_encoder_tip1.fit_transform(train_df['tip1'])
train_df['tip2_encoded'] = label_encoder_tip2.fit_transform(train_df['tip2'])

# 测试集使用训练集的编码器转换
test_df['tip1_encoded'] = label_encoder_tip1.transform(test_df['tip1'])
test_df['tip2_encoded'] = label_encoder_tip2.transform(test_df['tip2'])

# 4. 创建数据集
train_dataset = TipDataset(train_df)
test_dataset = TipDataset(test_df)

# ----------- 测试函数修正 -----------
def test(model, device, test_loader, criterion, label_encoder_tip1, label_encoder_tip2):  
    model.eval()  
    test_loss = 0  
    correct_tip1 = 0  
    correct_tip2 = 0  
    all_preds_tip1 = []  
    all_targets_tip1 = []  
    all_preds_tip2 = []  
    all_targets_tip2 = []  

    with torch.no_grad():  
        for data, target_tip1, target_tip2 in test_loader:  
            data, target_tip1, target_tip2 = data.to(device), target_tip1.to(device), target_tip2.to(device)  
            output_tip1, output_tip2 = model(data)  
            
            # 修正损失计算：每个batch计算的是平均损失
            loss_tip1 = criterion(output_tip1, target_tip1)  
            loss_tip2 = criterion(output_tip2, target_tip2)  
            test_loss += (loss_tip1.item() + loss_tip2.item())  # 累加batch的平均损失  

            # 原有准确率计算保持不变...
            pred_tip1 = output_tip1.argmax(dim=1, keepdim=True)  
            pred_tip2 = output_tip2.argmax(dim=1, keepdim=True)  

            correct_tip1 += pred_tip1.eq(target_tip1.view_as(pred_tip1)).sum().item()  
            correct_tip2 += pred_tip2.eq(target_tip2.view_as(pred_tip2)).sum().item()  

            all_preds_tip1.extend(pred_tip1.cpu().numpy().flatten())  
            all_targets_tip1.extend(target_tip1.cpu().numpy())  
            all_preds_tip2.extend(pred_tip2.cpu().numpy().flatten())  
            all_targets_tip2.extend(target_tip2.cpu().numpy())  

    # 关键修正：总损失 = 各batch平均损失之和 / batch数量
    test_loss /= len(test_loader)  # 不再是 len(test_loader.dataset)
    
    accuracy_tip1 = 100. * correct_tip1 / len(test_loader.dataset)  
    accuracy_tip2 = 100. * correct_tip2 / len(test_loader.dataset)  
    print(f'\nTest set: Average loss: {test_loss:.4f}, Accuracy tip1: {accuracy_tip1:.2f}%, Accuracy tip2: {accuracy_tip2:.2f}%\n')  

    # 分类报告使用训练集的classes_
    class_names_tip1 = label_encoder_tip1.classes_  
    class_names_tip2 = label_encoder_tip2.classes_  

    # 原有报告生成逻辑保持不变...
    report_tip1 = classification_report(all_targets_tip1, all_preds_tip1, target_names=class_names_tip1, zero_division=0)  
    print("Classification Report for tip1:\n", report_tip1)  

    report_tip2 = classification_report(all_targets_tip2, all_preds_tip2, target_names=class_names_tip2, zero_division=0)  
    print("Classification Report for tip2:\n", report_tip2)  

    cm_tip1 = confusion_matrix(all_targets_tip1, all_preds_tip1)  
    print("Confusion Matrix for tip1:\n", cm_tip1)  

    cm_tip2 = confusion_matrix(all_targets_tip2, all_preds_tip2)  
    print("Confusion Matrix for tip2:\n", cm_tip2)  

    return accuracy_tip1, accuracy_tip2  

# ----------- 主函数调整 -----------
if __name__ == "__main__":  
    # 数据加载器（保持不变）
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  

    # 模型初始化（注意类别数使用编码后的类别数）
    model = TransformerModel(
        input_dim, 
        num_heads, 
        num_layers,
        num_classes_tip1=len(label_encoder_tip1.classes_),  # 使用训练集的类别数
        num_classes_tip2=len(label_encoder_tip2.classes_)
    ).to(device)  

    # 训练和测试循环（保持不变）
    best_accuracy_tip1 = 0.0  
    best_accuracy_tip2 = 0.0  
    for epoch in range(1, num_epochs + 1):  
        train(model, device, train_loader, optimizer, criterion, epoch)  
        accuracy_tip1, accuracy_tip2 = test(
            model, device, test_loader, criterion, 
            label_encoder_tip1, label_encoder_tip2  # 传入训练集的编码器
        )  
        # 原有模型保存逻辑保持不变...